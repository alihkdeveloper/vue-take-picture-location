{"ast":null,"code":"import { createElementVNode as _createElementVNode, createStaticVNode as _createStaticVNode } from \"vue\";\nconst _hoisted_1 = /*#__PURE__*/_createStaticVNode(\"<select name=\\\"\\\" id=\\\"micSelect\\\"></select><select id=\\\"visSelect\\\"><option value=\\\"frequencybars\\\">Bar</option><option value=\\\"sinewave\\\">Wave</option><option value=\\\"circle\\\">Circle</option></select><a id=\\\"download\\\">Download</a><div class=\\\"audio-controls\\\"><button id=\\\"record\\\">Record</button><button id=\\\"stop\\\">Stop</button><audio id=\\\"audio\\\" controls></audio></div><div id=\\\"msg\\\">Recording...</div><canvas width=\\\"500\\\" height=\\\"300\\\"></canvas>\", 6);\nexport function render(_ctx, _cache, $props, $setup, $data, $options) {\n  return _hoisted_1;\n}","map":{"version":3,"names":["_hoisted_1"],"sources":["D:\\Project\\Nerd_herd\\accounting\\accounting\\src\\components\\RecordVoice.vue"],"sourcesContent":["<template>\r\n\t<select name=\"\" id=\"micSelect\"></select>\r\n\r\n\t<select id=\"visSelect\">\r\n\t\t<option value=\"frequencybars\">Bar</option>\r\n\t\t<option value=\"sinewave\">Wave</option>\r\n\t\t<option value=\"circle\">Circle</option>\r\n\t</select>\r\n\r\n\t<a id=\"download\">Download</a>\r\n\r\n\t<div class=\"audio-controls\">\r\n\t\t<button id=\"record\">Record</button>\r\n\t\t<button id=\"stop\">Stop</button>\r\n\t\t<audio id=\"audio\" controls></audio>\r\n\t</div>\r\n\r\n\t<div id=\"msg\">Recording...</div>\r\n\t<canvas width=\"500\" height=\"300\"></canvas>\r\n</template>\r\n\r\n<script>\r\nexport default (async () => {\r\n\tlet leftchannel = [];\r\n\tlet rightchannel = [];\r\n\tlet recorder = null;\r\n\tlet recording = false;\r\n\tlet recordingLength = 0;\r\n\tlet volume = null;\r\n\tlet audioInput = null;\r\n\tlet sampleRate = null;\r\n\tlet AudioContext = window.AudioContext || window.webkitAudioContext;\r\n\tlet context = null;\r\n\tlet analyser = null;\r\n\tlet canvas = document.querySelector(\"canvas\");\r\n\tlet canvasCtx = canvas.getContext(\"2d\");\r\n\tlet visualSelect = document.querySelector(\"#visSelect\");\r\n\tlet micSelect = document.querySelector(\"#micSelect\");\r\n\tlet stream = null;\r\n\tlet tested = false;\r\n\r\n\ttry {\r\n\t\twindow.stream = stream = await getStream();\r\n\t\tconsole.log(\"Got stream\");\r\n\t} catch (err) {\r\n\t\talert(\"Issue getting mic\", err);\r\n\t}\r\n\r\n\tconst deviceInfos = await navigator.mediaDevices.enumerateDevices();\r\n\r\n\tvar mics = [];\r\n\tfor (let i = 0; i !== deviceInfos.length; ++i) {\r\n\t\tlet deviceInfo = deviceInfos[i];\r\n\t\tif (deviceInfo.kind === \"audioinput\") {\r\n\t\t\tmics.push(deviceInfo);\r\n\t\t\tlet label = deviceInfo.label || \"Microphone \" + mics.length;\r\n\t\t\tconsole.log(\"Mic \", label + \" \" + deviceInfo.deviceId);\r\n\t\t\tconst option = document.createElement(\"option\");\r\n\t\t\toption.value = deviceInfo.deviceId;\r\n\t\t\toption.text = label;\r\n\t\t\tmicSelect.appendChild(option);\r\n\t\t}\r\n\t}\r\n\r\n\tfunction getStream(constraints) {\r\n\t\tif (!constraints) {\r\n\t\t\tconstraints = {audio: true, video: false};\r\n\t\t}\r\n\t\treturn navigator.mediaDevices.getUserMedia(constraints);\r\n\t}\r\n\r\n\tsetUpRecording();\r\n\r\n\tfunction setUpRecording() {\r\n\t\tcontext = new AudioContext();\r\n\t\tsampleRate = context.sampleRate;\r\n\r\n\t\t// creates a gain node\r\n\t\tvolume = context.createGain();\r\n\r\n\t\t// creates an audio node from teh microphone incoming stream\r\n\t\taudioInput = context.createMediaStreamSource(stream);\r\n\r\n\t\t// Create analyser\r\n\t\tanalyser = context.createAnalyser();\r\n\r\n\t\t// connect audio input to the analyser\r\n\t\taudioInput.connect(analyser);\r\n\r\n\t\t// connect analyser to the volume control\r\n\t\t// analyser.connect(volume);\r\n\r\n\t\tlet bufferSize = 2048;\r\n\t\tlet recorder = context.createScriptProcessor(bufferSize, 2, 2);\r\n\r\n\t\t// we connect the volume control to the processor\r\n\t\t// volume.connect(recorder);\r\n\r\n\t\tanalyser.connect(recorder);\r\n\r\n\t\t// finally connect the processor to the output\r\n\t\trecorder.connect(context.destination);\r\n\r\n\t\trecorder.onaudioprocess = function (e) {\r\n\t\t\t// Check\r\n\t\t\tif (!recording) return;\r\n\t\t\t// Do something with the data, i.e Convert this to WAV\r\n\t\t\tconsole.log(\"recording\");\r\n\t\t\tlet left = e.inputBuffer.getChannelData(0);\r\n\t\t\tlet right = e.inputBuffer.getChannelData(1);\r\n\t\t\tif (!tested) {\r\n\t\t\t\ttested = true;\r\n\t\t\t\t// if this reduces to 0 we are not getting any sound\r\n\t\t\t\tif (!left.reduce((a, b) => a + b)) {\r\n\t\t\t\t\talert(\"There seems to be an issue with your Mic\");\r\n\t\t\t\t\t// clean up;\r\n\t\t\t\t\tstop();\r\n\t\t\t\t\tstream.getTracks().forEach(function (track) {\r\n\t\t\t\t\t\ttrack.stop();\r\n\t\t\t\t\t});\r\n\t\t\t\t\tcontext.close();\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\t// we clone the samples\r\n\t\t\tleftchannel.push(new Float32Array(left));\r\n\t\t\trightchannel.push(new Float32Array(right));\r\n\t\t\trecordingLength += bufferSize;\r\n\t\t};\r\n\t\tvisualize();\r\n\t}\r\n\r\n\tfunction mergeBuffers(channelBuffer, recordingLength) {\r\n\t\tlet result = new Float32Array(recordingLength);\r\n\t\tlet offset = 0;\r\n\t\tlet lng = channelBuffer.length;\r\n\t\tfor (let i = 0; i < lng; i++) {\r\n\t\t\tlet buffer = channelBuffer[i];\r\n\t\t\tresult.set(buffer, offset);\r\n\t\t\toffset += buffer.length;\r\n\t\t}\r\n\t\treturn result;\r\n\t}\r\n\r\n\tfunction interleave(leftChannel, rightChannel) {\r\n\t\tlet length = leftChannel.length + rightChannel.length;\r\n\t\tlet result = new Float32Array(length);\r\n\r\n\t\tlet inputIndex = 0;\r\n\r\n\t\tfor (let index = 0; index < length; ) {\r\n\t\t\tresult[index++] = leftChannel[inputIndex];\r\n\t\t\tresult[index++] = rightChannel[inputIndex];\r\n\t\t\tinputIndex++;\r\n\t\t}\r\n\t\treturn result;\r\n\t}\r\n\r\n\tfunction writeUTFBytes(view, offset, string) {\r\n\t\tlet lng = string.length;\r\n\t\tfor (let i = 0; i < lng; i++) {\r\n\t\t\tview.setUint8(offset + i, string.charCodeAt(i));\r\n\t\t}\r\n\t}\r\n\r\n\tfunction start() {\r\n\t\trecording = true;\r\n\t\tdocument.querySelector(\"#msg\").style.visibility = \"visible\";\r\n\t\t// reset the buffers for the new recording\r\n\t\tleftchannel.length = rightchannel.length = 0;\r\n\t\trecordingLength = 0;\r\n\t\tconsole.log(\"context: \", !!context);\r\n\t\tif (!context) setUpRecording();\r\n\t}\r\n\r\n\tfunction stop() {\r\n\t\tconsole.log(\"Stop\");\r\n\t\trecording = false;\r\n\t\tdocument.querySelector(\"#msg\").style.visibility = \"hidden\";\r\n\r\n\t\t// we flat the left and right channels down\r\n\t\tlet leftBuffer = mergeBuffers(leftchannel, recordingLength);\r\n\t\tlet rightBuffer = mergeBuffers(rightchannel, recordingLength);\r\n\t\t// we interleave both channels together\r\n\t\tlet interleaved = interleave(leftBuffer, rightBuffer);\r\n\r\n\t\t///////////// WAV Encode /////////////////\r\n\t\t// from http://typedarray.org/from-microphone-to-wav-with-getusermedia-and-web-audio/\r\n\t\t//\r\n\r\n\t\t// we create our wav file\r\n\t\tlet buffer = new ArrayBuffer(44 + interleaved.length * 2);\r\n\t\tlet view = new DataView(buffer);\r\n\r\n\t\t// RIFF chunk descriptor\r\n\t\twriteUTFBytes(view, 0, \"RIFF\");\r\n\t\tview.setUint32(4, 44 + interleaved.length * 2, true);\r\n\t\twriteUTFBytes(view, 8, \"WAVE\");\r\n\t\t// FMT sub-chunk\r\n\t\twriteUTFBytes(view, 12, \"fmt \");\r\n\t\tview.setUint32(16, 16, true);\r\n\t\tview.setUint16(20, 1, true);\r\n\t\t// stereo (2 channels)\r\n\t\tview.setUint16(22, 2, true);\r\n\t\tview.setUint32(24, sampleRate, true);\r\n\t\tview.setUint32(28, sampleRate * 4, true);\r\n\t\tview.setUint16(32, 4, true);\r\n\t\tview.setUint16(34, 16, true);\r\n\t\t// data sub-chunk\r\n\t\twriteUTFBytes(view, 36, \"data\");\r\n\t\tview.setUint32(40, interleaved.length * 2, true);\r\n\r\n\t\t// write the PCM samples\r\n\t\tlet lng = interleaved.length;\r\n\t\tlet index = 44;\r\n\t\tlet volume = 1;\r\n\t\tfor (let i = 0; i < lng; i++) {\r\n\t\t\tview.setInt16(index, interleaved[i] * (0x7fff * volume), true);\r\n\t\t\tindex += 2;\r\n\t\t}\r\n\r\n\t\t// our final binary blob\r\n\t\tconst blob = new Blob([view], {type: \"audio/wav\"});\r\n\r\n\t\tconst audioUrl = URL.createObjectURL(blob);\r\n\t\tconsole.log(\"BLOB \", blob);\r\n\t\tconsole.log(\"URL \", audioUrl);\r\n\t\tdocument.querySelector(\"#audio\").setAttribute(\"src\", audioUrl);\r\n\t\tconst link = document.querySelector(\"#download\");\r\n\t\tlink.setAttribute(\"href\", audioUrl);\r\n\t\tlink.download = \"output.wav\";\r\n\t}\r\n\r\n\t// Visualizer function from\r\n\t// https://webaudiodemos.appspot.com/AudioRecorder/index.html\r\n\t//\r\n\tfunction visualize() {\r\n\t\tWIDTH = canvas.width;\r\n\t\tHEIGHT = canvas.height;\r\n\t\tCENTERX = canvas.width / 2;\r\n\t\tCENTERY = canvas.height / 2;\r\n\r\n\t\tlet visualSetting = visualSelect.value;\r\n\t\tconsole.log(visualSetting);\r\n\t\tif (!analyser) return;\r\n\r\n\t\tif (visualSetting === \"sinewave\") {\r\n\t\t\tanalyser.fftSize = 2048;\r\n\t\t\tvar bufferLength = analyser.fftSize;\r\n\t\t\tconsole.log(bufferLength);\r\n\t\t\tvar dataArray = new Uint8Array(bufferLength);\r\n\r\n\t\t\tcanvasCtx.clearRect(0, 0, WIDTH, HEIGHT);\r\n\r\n\t\t\tvar draw = function () {\r\n\t\t\t\tdrawVisual = requestAnimationFrame(draw);\r\n\r\n\t\t\t\tanalyser.getByteTimeDomainData(dataArray);\r\n\r\n\t\t\t\tcanvasCtx.fillStyle = \"rgb(200, 200, 200)\";\r\n\t\t\t\tcanvasCtx.fillRect(0, 0, WIDTH, HEIGHT);\r\n\r\n\t\t\t\tcanvasCtx.lineWidth = 2;\r\n\t\t\t\tcanvasCtx.strokeStyle = \"rgb(0, 0, 0)\";\r\n\r\n\t\t\t\tcanvasCtx.beginPath();\r\n\r\n\t\t\t\tvar sliceWidth = (WIDTH * 1.0) / bufferLength;\r\n\t\t\t\tvar x = 0;\r\n\r\n\t\t\t\tfor (var i = 0; i < bufferLength; i++) {\r\n\t\t\t\t\tvar v = dataArray[i] / 128.0;\r\n\t\t\t\t\tvar y = (v * HEIGHT) / 2;\r\n\r\n\t\t\t\t\tif (i === 0) {\r\n\t\t\t\t\t\tcanvasCtx.moveTo(x, y);\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\tcanvasCtx.lineTo(x, y);\r\n\t\t\t\t\t}\r\n\r\n\t\t\t\t\tx += sliceWidth;\r\n\t\t\t\t}\r\n\r\n\t\t\t\tcanvasCtx.lineTo(canvas.width, canvas.height / 2);\r\n\t\t\t\tcanvasCtx.stroke();\r\n\t\t\t};\r\n\r\n\t\t\tdraw();\r\n\t\t} else if (visualSetting == \"frequencybars\") {\r\n\t\t\tanalyser.fftSize = 64;\r\n\t\t\tvar bufferLengthAlt = analyser.frequencyBinCount;\r\n\t\t\tconsole.log(bufferLengthAlt);\r\n\t\t\tvar dataArrayAlt = new Uint8Array(bufferLengthAlt);\r\n\r\n\t\t\tcanvasCtx.clearRect(0, 0, WIDTH, HEIGHT);\r\n\r\n\t\t\tvar drawAlt = function () {\r\n\t\t\t\tdrawVisual = requestAnimationFrame(drawAlt);\r\n\r\n\t\t\t\tanalyser.getByteFrequencyData(dataArrayAlt);\r\n\r\n\t\t\t\tcanvasCtx.fillStyle = \"rgb(0, 0, 0)\";\r\n\t\t\t\tcanvasCtx.fillRect(0, 0, WIDTH, HEIGHT);\r\n\r\n\t\t\t\tvar barWidth = WIDTH / bufferLengthAlt;\r\n\t\t\t\tvar barHeight;\r\n\t\t\t\tvar x = 0;\r\n\r\n\t\t\t\tfor (var i = 0; i < bufferLengthAlt; i++) {\r\n\t\t\t\t\tbarHeight = dataArrayAlt[i];\r\n\r\n\t\t\t\t\tcanvasCtx.fillStyle = \"rgb(\" + (barHeight + 100) + \",50,50)\";\r\n\t\t\t\t\tcanvasCtx.fillRect(\r\n\t\t\t\t\t\tx,\r\n\t\t\t\t\t\tHEIGHT - barHeight / 2,\r\n\t\t\t\t\t\tbarWidth,\r\n\t\t\t\t\t\tbarHeight / 2\r\n\t\t\t\t\t);\r\n\r\n\t\t\t\t\tx += barWidth + 1;\r\n\t\t\t\t}\r\n\t\t\t};\r\n\r\n\t\t\tdrawAlt();\r\n\t\t} else if (visualSetting == \"circle\") {\r\n\t\t\tanalyser.fftSize = 32;\r\n\t\t\tlet bufferLength = analyser.frequencyBinCount;\r\n\t\t\tconsole.log(bufferLength);\r\n\t\t\tlet dataArray = new Uint8Array(bufferLength);\r\n\r\n\t\t\tcanvasCtx.clearRect(0, 0, WIDTH, HEIGHT);\r\n\r\n\t\t\tlet draw = () => {\r\n\t\t\t\tdrawVisual = requestAnimationFrame(draw);\r\n\r\n\t\t\t\tanalyser.getByteFrequencyData(dataArray);\r\n\t\t\t\tcanvasCtx.fillStyle = \"rgb(0, 0, 0)\";\r\n\t\t\t\tcanvasCtx.fillRect(0, 0, WIDTH, HEIGHT);\r\n\r\n\t\t\t\t// let radius = dataArray.reduce((a,b) => a + b) / bufferLength;\r\n\t\t\t\tlet radius = dataArray[2] / 2;\r\n\t\t\t\tif (radius < 20) radius = 20;\r\n\t\t\t\tif (radius > 100) radius = 100;\r\n\t\t\t\t// console.log('Radius ', radius)\r\n\t\t\t\tcanvasCtx.beginPath();\r\n\t\t\t\tcanvasCtx.arc(CENTERX, CENTERY, radius, 0, 2 * Math.PI, false);\r\n\t\t\t\t// canvasCtx.fillStyle = 'rgb(50,50,' + (radius+100) +')';\r\n\t\t\t\t// canvasCtx.fill();\r\n\t\t\t\tcanvasCtx.lineWidth = 6;\r\n\t\t\t\tcanvasCtx.strokeStyle = \"rgb(50,50,\" + (radius + 100) + \")\";\r\n\t\t\t\tcanvasCtx.stroke();\r\n\t\t\t};\r\n\t\t\tdraw();\r\n\t\t}\r\n\t}\r\n\r\n\tvisualSelect.onchange = function () {\r\n\t\twindow.cancelAnimationFrame(drawVisual);\r\n\t\tvisualize();\r\n\t};\r\n\r\n\tmicSelect.onchange = async (e) => {\r\n\t\tconsole.log(\"now use device \", micSelect.value);\r\n\t\tstream.getTracks().forEach(function (track) {\r\n\t\t\ttrack.stop();\r\n\t\t});\r\n\t\tcontext.close();\r\n\r\n\t\tstream = await getStream({\r\n\t\t\taudio: {\r\n\t\t\t\tdeviceId: {exact: micSelect.value},\r\n\t\t\t},\r\n\t\t\tvideo: false,\r\n\t\t});\r\n\t\tsetUpRecording();\r\n\t};\r\n\r\n\tfunction pause() {\r\n\t\trecording = false;\r\n\t\tcontext.suspend();\r\n\t}\r\n\r\n\tfunction resume() {\r\n\t\trecording = true;\r\n\t\tcontext.resume();\r\n\t}\r\n\r\n\tdocument.querySelector(\"#record\").onclick = (e) => {\r\n\t\tconsole.log(\"Start recording\");\r\n\t\tstart();\r\n\t};\r\n\r\n\tdocument.querySelector(\"#stop\").onclick = (e) => {\r\n\t\tstop();\r\n\t};\r\n})();\r\n</script>\r\n"],"mappings":";;;SACCA,UAAwC"},"metadata":{},"sourceType":"module","externalDependencies":[]}